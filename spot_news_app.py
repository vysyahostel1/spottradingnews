import streamlit as st
import feedparser
import requests
from datetime import datetime

# ğŸ” Telegram API
bot_token = "8376336695:AAEUqfYB2-nWXy4ozOaxeznEmvtRrTJ5AbI"
chat_id = "@spot_tradingnews"

# ğŸŒ RSS Feeds
feeds = [
    "https://www.moneycontrol.com/rss/news.xml",
    "https://economictimes.indiatimes.com/rssfeedsdefault.cms",
    "https://feeds.reuters.com/reuters/businessNews",
    "https://feeds.reuters.com/reuters/marketsNews",
    "https://www.business-standard.com/rss/home_page_top_stories.rss",
    "https://www.livemint.com/rss/news"
]

# ğŸ“Š Sentiment tagging
def detect_sentiment(text):
    text = text.lower()
    if any(word in text for word in ["surge", "gain", "rise", "up", "record high"]):
        return "Bullish ğŸ“ˆ"
    elif any(word in text for word in ["fall", "drop", "decline", "down", "plunge"]):
        return "Bearish ğŸ“‰"
    else:
        return "Neutral âš–ï¸"

# ğŸ· Sector tagging
def tag_sector(text):
    text = text.lower()
    if any(word in text for word in ["bank", "loan", "insurance", "finance", "nifty"]):
        return "Finance ğŸ¦"
    elif any(word in text for word in ["auto", "vehicle", "ev", "car", "bike"]):
        return "Auto ğŸš—"
    elif any(word in text for word in ["power", "energy", "solar", "electricity"]):
        return "Energy âš¡"
    elif any(word in text for word in ["gold", "silver", "commodity", "metal"]):
        return "Commodities ğŸª™"
    elif any(word in text for word in ["tech", "software", "ai", "it", "startup"]):
        return "Technology ğŸ’»"
    elif any(word in text for word in ["real estate", "property", "housing"]):
        return "Real Estate ğŸ˜ï¸"
    else:
        return "General ğŸ“°"

# ğŸŒ Country detection
def detect_country(text, source):
    text = text.lower()
    source = source.lower()
    if "india" in text or source in ["moneycontrol.com", "economictimes.indiatimes.com", "livemint.com", "business-standard.com"]:
        return "India ğŸ‡®ğŸ‡³"
    else:
        return "Global ğŸŒ"

# ğŸ§  Point-wise summarizer
def summarize_to_points(text):
    sentences = text.split(". ")
    return [s.strip() for s in sentences if len(s.strip()) > 30][:5]

# ğŸ“² Telegram sector-wise batching
def push_sector_batches(sector_dict):
    for sector, items in sector_dict.items():
        if not items:
            continue
        message = f"ğŸ“¢ *{sector} News Update*\n\n"
        for h in items:
            message += f"*ğŸ“° {h['title']}*\n"
            message += f"ğŸ•’ {h['timestamp']} | ğŸŒ {h['country']}\n"
            for p in h['points']:
                message += f"â€¢ {p}\n"
            message += f"\nğŸ“Š {h['sentiment']} | ğŸ”— `{h['source']}`\n\n"
        requests.post(
            f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
            data={"chat_id": CHAT_ID, "text": message, "parse_mode": "Markdown"}
        )

# ğŸ§© Streamlit UI
st.set_page_config(page_title="Spot Trading â€“ Auto News Pulse", layout="wide")
st.title("ğŸ“ˆ Spot Trading â€“ Daily Market Pulse")
st.write(f"ğŸ—“ï¸ {datetime.now().strftime('%d %b %Y, %I:%M %p')}")

refresh_minutes = st.slider("ğŸ” Auto-refresh every X minutes", 1, 30, 5)

if "seen" not in st.session_state:
    st.session_state.seen = set()
if "last_refresh" not in st.session_state:
    st.session_state.last_refresh = datetime.now()

headlines = []
sector_batches = {}

# ğŸ”„ Refresh logic
if datetime.now() - st.session_state.last_refresh > timedelta(minutes=refresh_minutes):
    st.session_state.last_refresh = datetime.now()
    st.experimental_rerun()

for url in feeds:
    try:
        feed = feedparser.parse(url)
    except Exception as e:
        st.warning(f"âš ï¸ Failed to load feed: {url}\nError: {e}")
        continue

    for entry in feed.entries[:3]:
        headline = entry.title
        link = entry.link
        source = link.split("/")[2]
        full_text = entry.get("summary", "")
        if headline not in st.session_state.seen:
            st.session_state.seen.add(headline)
            points = summarize_to_points(full_text)
            sentiment = detect_sentiment(full_text)
            sector = tag_sector(full_text)
            country = detect_country(full_text, source)
            timestamp = datetime.now().strftime("%d %b %Y, %I:%M %p")

            st.markdown(f"### ğŸ“° {headline}")
            st.write(f"ğŸ•’ {timestamp} | ğŸŒ {country}")
            for p in points:
                st.write(f"â€¢ {p}")
            st.write(f"ğŸ“Š Sentiment: {sentiment} | ğŸ· Sector: {sector}")
            st.markdown(f"ğŸ”— Source: `{source}`")
            st.markdown(f"[Read more]({link})")
            st.divider()

            item = {
                "title": headline,
                "points": points,
                "sentiment": sentiment,
                "source": source,
                "sector": sector,
                "timestamp": timestamp,
                "country": country
            }

            headlines.append(item)
            sector_batches.setdefault(sector, []).append(item)

# ğŸš€ Push to Telegram
if headlines:
    push_sector_batches(sector_batches)
    st.success("âœ… Sector-wise news pushed to Telegram!")
else:
    st.info("No new headlines found.")


